{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-deadline",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from io import TextIOWrapper, StringIO\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from typing import List\n",
    "from uid3.reading import Reading\n",
    "from uid3.instance import Instance\n",
    "from uid3.att_stats import AttStats\n",
    "from uid3.attribute import Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Data:\n",
    "    REAL_DOMAIN = '@REAL'\n",
    "\n",
    "    def __init__(self, name: str = None, attributes: List[Attribute] = None, instances: List[Instance] = None):\n",
    "        self.name = name\n",
    "        self.attributes = attributes\n",
    "        self.instances = instances\n",
    "\n",
    "    def filter_nominal_attribute_value(self, at: Attribute, value: str) -> 'Data':\n",
    "        new_instances = []\n",
    "        new_attributes = self.attributes.copy()\n",
    "        new_attributes.remove(at)\n",
    "\n",
    "        for i in self.instances:\n",
    "            reading = i.get_reading_for_attribute(at.get_name())\n",
    "            instance_val = reading.get_most_probable().get_name()\n",
    "            if instance_val == value:\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "\n",
    "        return Data(self.name, new_attributes, new_instances)\n",
    "\n",
    "    def filter_numeric_attribute_value(self, at: Attribute, value: str, less_than: bool) -> 'Data':\n",
    "        new_instances = []\n",
    "        new_attributes = self.attributes.copy()\n",
    "        new_attributes.remove(at)\n",
    "\n",
    "        for i in self.instances:\n",
    "            reading = i.get_reading_for_attribute(at.get_name())\n",
    "            instance_val = reading.get_most_probable().get_name()\n",
    "            if less_than and float(instance_val) < float(value):\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "            elif not less_than and float(instance_val) >= float(value):\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "\n",
    "        return Data(self.name, new_attributes, new_instances)\n",
    "\n",
    "    def get_attribute_of_name(self, att_name: str) -> Attribute:\n",
    "        for at in self.attributes:\n",
    "            if at.get_name() == att_name:\n",
    "                return at\n",
    "        return None\n",
    "\n",
    "    def to_arff_most_probable(self) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            for r in i.get_readings():\n",
    "                result += r.get_most_probable().get_name()\n",
    "                result += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += '\\n'\n",
    "        return result\n",
    "\n",
    "    def to_arff_skip_instance(self, epsilon: float) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            partial = ''\n",
    "            for r in i.get_readings():\n",
    "                if r.get_most_probable().get_confidence() > epsilon:\n",
    "                    partial += r.get_most_probable().get_name()\n",
    "                else:\n",
    "                    break\n",
    "                partial += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += partial + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def to_arff_skip_value(self, epsilon: float) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            partial = ''\n",
    "            for r in i.get_readings():\n",
    "                if r.get_most_probable().get_confidence() > epsilon:\n",
    "                    partial += r.get_most_probable().get_name()\n",
    "                else:\n",
    "                    partial += '?'\n",
    "                partial += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += partial + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def to_uarff(self) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            result += i.to_arff() + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def calculate_statistics(self, att: Attribute) -> AttStats:\n",
    "        return AttStats.get_statistics(att, self)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_uarff_from_buffer(br: (TextIOWrapper, StringIO)): # TODO throws IOException, ParseException\n",
    "        atts = []\n",
    "        insts = []\n",
    "        name = br.readline().split('@relation')[1].strip()\n",
    "        for line in br:\n",
    "            if len(line) == 1:\n",
    "                continue\n",
    "            att_split = line.strip().split('@attribute')\n",
    "            if len(att_split) > 1:\n",
    "                att = Data.parse_attribute(att_split[1].strip())\n",
    "                atts.append(att)\n",
    "            elif line.strip() == '@data':\n",
    "                break\n",
    "\n",
    "        # read instances\n",
    "        for line in br:\n",
    "            inst = Data.parse_instances(atts, line.strip())\n",
    "            insts.append(inst)\n",
    "\n",
    "        tmp_data = Data(name, atts, insts)\n",
    "        tmp_data.update_attribute_domains()\n",
    "        return tmp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def read_ucsv_from_dataframe(df: DataFrame, name: str):\n",
    "        atts = []\n",
    "        insts = []\n",
    "        cols = list(df.columns)\n",
    "        for col in cols:\n",
    "            records = set(df[col])\n",
    "            records = set(re.sub(r'\\[[0-9.]*]', '', str(rec)) for rec in records)\n",
    "            records = list(records)\n",
    "            if len(records) == 1:\n",
    "                records = records[0].split(';')\n",
    "            if len(records) > 10:\n",
    "                att = col + ' @REAL'  # mark as a real value\n",
    "            else:\n",
    "                att = str(records).strip(\"'\").strip('[').strip(']')\n",
    "                att = col + ' {' + att + '}'\n",
    "            att = Data.parse_attribute(att)\n",
    "            atts.append(att)\n",
    "\n",
    "        br = StringIO(df.to_string(index=False))\n",
    "        for line in br:\n",
    "            line = re.sub(' +', ',', line.strip())\n",
    "            inst = Data.parse_instances(atts, line)\n",
    "            insts.append(inst)\n",
    "\n",
    "        tmp_data = Data(name, atts, insts)\n",
    "        tmp_data.update_attribute_domains()\n",
    "        return tmp_data\n",
    "\n",
    "    def update_attribute_domains(self):\n",
    "        for a in self.get_attributes():\n",
    "            if a.get_type() == 'TYPE_NUMERICAL':\n",
    "                domain = self.get_domain_from_data(a, self.instances)\n",
    "                a.set_domain(domain)\n",
    "\n",
    "    def get_domain_from_data(self, a: Attribute, instances: List[Instance]):\n",
    "        domain = set()\n",
    "        for i in instances:\n",
    "            value = i.get_reading_for_attribute(a.get_name()).get_most_probable().get_name()\n",
    "            domain.add(value)\n",
    "        return domain\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_ucsv(filename: str):  # TODO: throws ParseException:\n",
    "        df = pd.read_csv(filename)\n",
    "        name = filename.split('/')[-1].split('.csv')[0]\n",
    "        out = Data.read_ucsv_from_dataframe(df, name)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_uarff(filename: str):  # TODO: throws ParseException:\n",
    "        try:\n",
    "            br = open(filename)\n",
    "        except OSError as e:\n",
    "            print(e) # TODO\n",
    "            return None\n",
    "        out = Data.read_uarff_from_buffer(br)\n",
    "        br.close()\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_uarff_from_string(uarff: str) -> 'Data': # TODO throws ParseException\n",
    "        try:\n",
    "            br = StringIO(uarff)\n",
    "        except OSError as e:\n",
    "            print(e)  # TODO\n",
    "            return None\n",
    "        out = Data.read_uarff_from_buffer(br)\n",
    "        br.close()\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_uarff_from_string(string: str, class_name: str) -> 'Data': # TODO throws ParseException\n",
    "        temp_data = Data.parse_uarff_from_string(string)\n",
    "        class_att = temp_data.get_attribute_of_name(class_name)\n",
    "        class_index = temp_data.attributes.index(class_att)\n",
    "\n",
    "        del temp_data.attributes[class_index]\n",
    "        temp_data.attributes.append(class_att)\n",
    "        # change order of reading for the att.\n",
    "        for i in temp_data.instances:\n",
    "            class_label = i.get_reading_for_attribute(class_att.get_name())\n",
    "            readings = i.get_readings()\n",
    "            del readings[class_index]\n",
    "            readings.append(class_label)\n",
    "            i.set_readings(readings)\n",
    "        return temp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_uarff_from_string(string: str, class_index: int) -> 'Data': # TODO throws ParseException\n",
    "        temp_data = Data.parse_uarff_from_string(string)\n",
    "        # change order of the attributes\n",
    "        class_att = temp_data.attributes[class_index]\n",
    "        del temp_data.attributes[class_index]\n",
    "        temp_data.attributes.append(class_att)\n",
    "        # change order of reading for the att.\n",
    "        for i in temp_data.instances:\n",
    "            class_label = i.get_reading_for_attribute(class_att.get_name())\n",
    "            readings = i.get_readings()\n",
    "            del readings[class_index]\n",
    "            readings.append(class_label)\n",
    "            i.set_readings(readings)\n",
    "        return temp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_uarff(filename: str, class_name: str) -> 'Data': # TODO throws ParseException\n",
    "        temp_data = Data.parse_uarff(filename)\n",
    "        class_att = temp_data.get_attribute_of_name(class_name)\n",
    "        class_index = temp_data.attributes.index(class_att)\n",
    "        del temp_data.attributes[class_index]\n",
    "        temp_data.attributes.append(class_att)\n",
    "        # change order of reading for the att.\n",
    "        for i in temp_data.instances:\n",
    "            class_label = i.get_reading_for_attribute(class_att.get_name())\n",
    "            readings = i.get_readings()\n",
    "            del readings[class_index]\n",
    "            readings.apppend(class_label)\n",
    "            i.set_readings(readings)\n",
    "        return temp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_uarff(filename: str, class_index: int) -> 'Data': # TODO throws ParseException\n",
    "        temp_data = Data.parse_uarff(filename)\n",
    "        # change order of the attribtues\n",
    "        class_att = temp_data.attributes[class_index]\n",
    "        del temp_data.attributes[class_index]\n",
    "        temp_data.attributes.append(class_att)\n",
    "        # change order of reading for the att.\n",
    "        for i in temp_data.instances:\n",
    "            class_label = i.get_reading_for_attribute(class_att.get_name())\n",
    "            readings = i.get_readings()\n",
    "            del readings[class_index]\n",
    "            readings.append(class_label)\n",
    "            i.set_readings(readings)\n",
    "        return temp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_instances(base_atts: List[Attribute], inst_def: str): # TODO throws ParseException\n",
    "        readings_defs = inst_def.split(',')\n",
    "        i = Instance()\n",
    "        if len(readings_defs) != len(base_atts):\n",
    "            pass\n",
    "            # TODO throw ParseException('Missing attribute definition, or value in line '+inst_def);\n",
    "\n",
    "        for reading, att in zip(readings_defs, base_atts):\n",
    "            r = Reading.parse_reading(att, reading)\n",
    "            i.add_reading(r)\n",
    "        return i\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_attribute(att_def: str):\n",
    "        name_boundary = int(att_def.index(' '))\n",
    "        type = Attribute.TYPE_NOMINAL\n",
    "        name = att_def[0:name_boundary]\n",
    "        domain = set()\n",
    "        untrimmed_domain = re.sub(r'[{}]', '',  att_def[name_boundary:]).split(',')\n",
    "        for value in untrimmed_domain:\n",
    "            if value.strip() == 'REAL_DOMAIN':\n",
    "                type = Attribute.TYPE_NUMERICAL\n",
    "                break\n",
    "            domain.add(value.strip())\n",
    "        return Attribute(name, domain, type)\n",
    "\n",
    "    def get_instances(self):\n",
    "        return self.instances.copy()\n",
    "\n",
    "    def get_attributes(self):\n",
    "        return self.attributes.copy()\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def get_class_attribute(self):\n",
    "        return self.attributes[-1] # get last element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
