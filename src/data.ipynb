{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-deadline",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from io import TextIOWrapper, StringIO\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from typing import List, Set\n",
    "\n",
    "from uid3.reading import Reading\n",
    "from uid3.instance import Instance\n",
    "from uid3.att_stats import AttStats\n",
    "from uid3.attribute import Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Data:\n",
    "    REAL_DOMAIN = '@REAL'\n",
    "\n",
    "    def __init__(self, name: str = None, attributes: List[Attribute] = None, instances: List[Instance] = None):\n",
    "        self.name = name\n",
    "        self.attributes = attributes\n",
    "        self.instances = instances\n",
    "\n",
    "    def filter_nominal_attribute_value(self, at: Attribute, value: str) -> 'Data':\n",
    "        new_instances = []\n",
    "        new_attributes = self.attributes.copy()\n",
    "        new_attributes.remove(at)\n",
    "\n",
    "        for i in self.instances:\n",
    "            reading = i.get_reading_for_attribute(at.get_name())\n",
    "            instance_val = reading.get_most_probable().get_name()\n",
    "            if instance_val == value:\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "\n",
    "        return Data(self.name, new_attributes, new_instances)\n",
    "\n",
    "    def filter_numeric_attribute_value(self, at: Attribute, value: str, less_than: bool) -> 'Data':\n",
    "        new_instances = []\n",
    "        new_attributes = self.attributes.copy()\n",
    "        new_attributes.remove(at)\n",
    "\n",
    "        for i in self.instances:\n",
    "            reading = i.get_reading_for_attribute(at.get_name())\n",
    "            instance_val = reading.get_most_probable().get_name()\n",
    "            if less_than and float(instance_val) < float(value):\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "            elif not less_than and float(instance_val) >= float(value):\n",
    "                new_readings = i.get_readings().copy()\n",
    "                new_readings.remove(reading)\n",
    "                new_instances.append(Instance(new_readings))\n",
    "\n",
    "        return Data(self.name, new_attributes, new_instances)\n",
    "\n",
    "    def get_attribute_of_name(self, att_name: str) -> Attribute:\n",
    "        for at in self.attributes:\n",
    "            if at.get_name() == att_name:\n",
    "                return at\n",
    "        return None\n",
    "\n",
    "    def to_arff_most_probable(self) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            for r in i.get_readings():\n",
    "                result += r.get_most_probable().get_name()\n",
    "                result += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += '\\n'\n",
    "        return result\n",
    "\n",
    "    def to_arff_skip_instance(self, epsilon: float) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            partial = ''\n",
    "            for r in i.get_readings():\n",
    "                if r.get_most_probable().get_confidence() > epsilon:\n",
    "                    partial += r.get_most_probable().get_name()\n",
    "                else:\n",
    "                    break\n",
    "                partial += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += partial + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def to_arff_skip_value(self, epsilon: float) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            partial = ''\n",
    "            for r in i.get_readings():\n",
    "                if r.get_most_probable().get_confidence() > epsilon:\n",
    "                    partial += r.get_most_probable().get_name()\n",
    "                else:\n",
    "                    partial += '?'\n",
    "                partial += ','\n",
    "            result = result[:-1]  # delete the last coma ','\n",
    "            result += partial + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def to_uarff(self) -> str:\n",
    "        result = '@relation ' + self.name + '\\n'\n",
    "        for at in self.attributes:\n",
    "            result += at.to_arff() + '\\n'\n",
    "\n",
    "        result += '@data\\n'\n",
    "\n",
    "        for i in self.instances:\n",
    "            result += i.to_arff() + '\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def calculate_statistics(self, att: Attribute) -> AttStats:\n",
    "        return AttStats.get_statistics(att, self)\n",
    "\n",
    "    @staticmethod\n",
    "    def __read_uarff_from_buffer(br: (TextIOWrapper, StringIO)) -> 'Data':  # TODO throws IOException, ParseException\n",
    "        atts = []\n",
    "        insts = []\n",
    "        name = br.readline().split('@relation')[1].strip()\n",
    "        for line in br:\n",
    "            if len(line) == 1:\n",
    "                continue\n",
    "            att_split = line.strip().split('@attribute')\n",
    "            if len(att_split) > 1:\n",
    "                att = Data.parse_attribute(att_split[1].strip())\n",
    "                atts.append(att)\n",
    "            elif line.strip() == '@data':\n",
    "                break\n",
    "\n",
    "        # read instances\n",
    "        for line in br:\n",
    "            inst = Data.parse_instances(atts, line.strip())\n",
    "            insts.append(inst)\n",
    "\n",
    "        tmp_data = Data(name, atts, insts)\n",
    "        tmp_data.update_attribute_domains()\n",
    "        return tmp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def __read_ucsv_from_dataframe(df: DataFrame, name: str) -> 'Data':\n",
    "        atts = []\n",
    "        insts = []\n",
    "        cols = list(df.columns)\n",
    "        for col in cols:\n",
    "            records = set(df[col])\n",
    "            records = set(re.sub(r'\\[[0-9.]*]', '', str(rec)) for rec in records)\n",
    "            records = list(records)\n",
    "            if len(records) == 1:\n",
    "                records = records[0].split(';')\n",
    "            if len(records) > 10:\n",
    "                att = col + ' @REAL'  # mark as a real value\n",
    "            else:\n",
    "                att = str(records).strip(\"'\").strip('[').strip(']')\n",
    "                att = col + ' {' + att + '}'\n",
    "            att = Data.parse_attribute(att)\n",
    "            atts.append(att)\n",
    "\n",
    "        br = StringIO(df.to_string(index=False))\n",
    "        for line in br:\n",
    "            line = re.sub(' +', ',', line.strip())\n",
    "            inst = Data.parse_instances(atts, line)\n",
    "            insts.append(inst)\n",
    "\n",
    "        tmp_data = Data(name, atts, insts)\n",
    "        tmp_data.update_attribute_domains()\n",
    "        return tmp_data\n",
    "\n",
    "    def update_attribute_domains(self):\n",
    "        for a in self.get_attributes():\n",
    "            if a.get_type() == 'TYPE_NUMERICAL':\n",
    "                domain = self.__get_domain_from_data(a, self.instances)\n",
    "                a.set_domain(domain)\n",
    "\n",
    "    def __get_domain_from_data(self, a: Attribute, instances: List[Instance]) -> Set[str]:\n",
    "        domain = set()\n",
    "        for i in instances:\n",
    "            value = i.get_reading_for_attribute(a.get_name()).get_most_probable().get_name()\n",
    "            domain.add(value)\n",
    "        return domain\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_ucsv(filename: str) -> 'Data':  # TODO: throws ParseException:\n",
    "        df = pd.read_csv(filename)\n",
    "        name = filename.split('/')[-1].split('.csv')[0]\n",
    "        out = Data.__read_ucsv_from_dataframe(df, name)\n",
    "        return out\n",
    "\n",
    "    @ staticmethod\n",
    "    def __parse(temp_data: 'Data', class_id: (int, str)) -> 'Data':\n",
    "        # if class name is given\n",
    "        if isinstance(class_id, str):\n",
    "            class_att = temp_data.get_attribute_of_name(class_id)\n",
    "            class_index = temp_data.attributes.index(class_att)\n",
    "\n",
    "        # if class index is given\n",
    "        elif isinstance(class_id, int):\n",
    "            class_index = class_id\n",
    "            class_att = temp_data.attributes[class_index]\n",
    "\n",
    "        del temp_data.attributes[class_index]\n",
    "        temp_data.attributes.append(class_att)\n",
    "        # change order of reading for the att.\n",
    "        for i in temp_data.instances:\n",
    "            class_label = i.get_reading_for_attribute(class_att.get_name())\n",
    "            readings = i.get_readings()\n",
    "            del readings[class_index]\n",
    "            readings.append(class_label)\n",
    "            i.set_readings(readings)\n",
    "        return temp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_uarff_from_string(string: str, class_id: (int, str) = None) -> 'Data':  # TODO throws ParseException\n",
    "        try:\n",
    "            br = StringIO(string)\n",
    "        except OSError as e:\n",
    "            print(e)  # TODO\n",
    "            return None\n",
    "        temp_data = Data.__read_uarff_from_buffer(br)\n",
    "        br.close()\n",
    "        if not class_id:\n",
    "            return temp_data\n",
    "\n",
    "        return Data.__parse(temp_data, class_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_uarff(filename: str, class_id: (int, str) = None) -> 'Data':  # TODO throws ParseException:\n",
    "        try:\n",
    "            br = open(filename)\n",
    "        except OSError as e:\n",
    "            print(e)  # TODO\n",
    "            return None\n",
    "        temp_data = Data.__read_uarff_from_buffer(br)\n",
    "        br.close()\n",
    "        if not class_id:\n",
    "            return temp_data\n",
    "\n",
    "        return Data.__parse(temp_data, class_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_instances(base_atts: List[Attribute], inst_def: str) -> Instance:  # TODO throws ParseException\n",
    "        readings_defs = inst_def.split(',')\n",
    "        i = Instance()\n",
    "        if len(readings_defs) != len(base_atts):\n",
    "            pass\n",
    "            # TODO throw ParseException('Missing attribute definition, or value in line '+inst_def);\n",
    "\n",
    "        for reading, att in zip(readings_defs, base_atts):\n",
    "            r = Reading.parse_reading(att, reading)\n",
    "            i.add_reading(r)\n",
    "        return i\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_attribute(att_def: str) -> Attribute:\n",
    "        name_boundary = int(att_def.index(' '))\n",
    "        type = Attribute.TYPE_NOMINAL\n",
    "        name = att_def[0:name_boundary]\n",
    "        domain = set()\n",
    "        untrimmed_domain = re.sub(r'[{}]', '',  att_def[name_boundary:]).split(',')\n",
    "        for value in untrimmed_domain:\n",
    "            if value.strip() == 'REAL_DOMAIN':\n",
    "                type = Attribute.TYPE_NUMERICAL\n",
    "                break\n",
    "            domain.add(value.strip())\n",
    "        return Attribute(name, domain, type)\n",
    "\n",
    "    def get_instances(self) -> List[Instance]:\n",
    "        return self.instances.copy()\n",
    "\n",
    "    def get_attributes(self) -> List[Attribute]:\n",
    "        return self.attributes.copy()\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "    def get_class_attribute(self) -> Attribute:\n",
    "        return self.attributes[-1]  # get last element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
